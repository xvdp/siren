{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "siren_video.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyN95QU4iamaDUzI1dh1Ot1C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xvdp/siren/blob/x_dev/siren_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPcStNVh5oMW"
      },
      "source": [
        "# Siren Video stress test\n",
        "Notes on tests for video\n",
        "\n",
        "**Loss** is $ (x - y)^2 $ Decreases in few iterations very quickly; most of the computation for a video is required to smooth the high frequency details and sharp boundaries.\n",
        "\n",
        "**Sampling** strategy differs from sampling of a single image. In the first case the image is loaded as a single instance. The current loaders load the video in RAM but cannot load entire data to GPU, choosing a single uniform random sample of size *batch_size*- which may be repeated - per epoch. (pass stragegy=-1)\n",
        "\n",
        "Ensuring complete non repeating sampling per epoch (strategy=1) results in worse performance, as does passing complete contiguous blocks of data. Possibly the repetition of some samples regularizes the loss preventing overfitting.\n",
        "\n",
        "**Batch size** will depend on GPU availability.\n",
        "Supplementary Info pg. 16\n",
        "\"*The Adam optimizer with a learning rate of1×10−4was used for all experi-ments. We set the batch size to fill the memory of the GPUs (roughly 160,000)\"\n",
        "\"We train the videos for 100,000 iterations, requiring approximately 15 hours.\"*\n",
        "\n",
        " Batch or sample size on this colab ~ 320000 - each iteration is taking 2s, making training of a small video, ~ 57 hours, a bit much. On a local machine with TitanGTX 24G - computation took 23 hours.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcgfVsjw9XLY",
        "outputId": "5ea19341-1b5f-4529-d00d-63f0302d02c7"
      },
      "source": [
        "!pip install git+https://github.com/xvdp/vidi.git\n",
        "!rm -rf siren/\n",
        "!git clone -b x_dev https://github.com/xvdp/siren.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/xvdp/vidi.git\n",
            "  Cloning https://github.com/xvdp/vidi.git to /tmp/pip-req-build-l5r_2ah3\n",
            "  Running command git clone -q https://github.com/xvdp/vidi.git /tmp/pip-req-build-l5r_2ah3\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from vidi==0.1) (1.19.5)\n",
            "Building wheels for collected packages: vidi\n",
            "  Building wheel for vidi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vidi: filename=vidi-0.1-cp37-none-any.whl size=25732 sha256=f38c84b923a070a9fecf9d309a7b29c0e304fc69d245275f7ff0d6148264875e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jymcdi54/wheels/eb/af/bf/d3d553233ac4ba8401e2c03425734897d87fcb779db2b27f14\n",
            "Successfully built vidi\n",
            "Installing collected packages: vidi\n",
            "Successfully installed vidi-0.1\n",
            "Cloning into 'siren'...\n",
            "remote: Enumerating objects: 299, done.\u001b[K\n",
            "remote: Counting objects: 100% (106/106), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 299 (delta 61), reused 65 (delta 29), pack-reused 193\u001b[K\n",
            "Receiving objects: 100% (299/299), 10.61 MiB | 20.23 MiB/s, done.\n",
            "Resolving deltas: 100% (128/128), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAs7krUR-Vp5"
      },
      "source": [
        "import os\n",
        "import os.path as osp\n",
        "import yaml\n",
        "import torch\n",
        "os.chdir(\"siren\")\n",
        "import x_utils\n",
        "import x_dataio\n",
        "import x_modules\n",
        "from x_training import train, _continue, load_last_checkpoint, _prevent_overwrite"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y85WrjaiH8bB"
      },
      "source": [
        "## check available GPU and CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q9EhyzL-ozn",
        "outputId": "96ab0179-53b6-4f67-8a55-50cb56025277"
      },
      "source": [
        "x_utils.GPUse(), x_utils.CPUse()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(GPU: ({'total': 15109, 'used': 0, 'available': 15109, 'percent': 0.0, 'units': 'MB'}),\n",
              " CPU: ({'total': 12993, 'used': 610, 'available': 12110, 'percent': 6.8, 'units': 'MB'}))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YGtG8I7IDZf"
      },
      "source": [
        "## download cat video\n",
        "from https://drive.google.com/drive/u/0/folders/1_iq__37-hw7FJOEUK1tX7mdp8SKB368K"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iBwwA_F-LlF",
        "outputId": "62d0d21e-56ab-4380-a6a5-78cbdf63b831"
      },
      "source": [
        "#https://drive.google.com/file/d/1ZCr6HTrNu8f6T-nyIbToYXHMOKU88f7P/view?usp=sharing\n",
        "!gdown --id 1ZCr6HTrNu8f6T-nyIbToYXHMOKU88f7P "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZCr6HTrNu8f6T-nyIbToYXHMOKU88f7P\n",
            "To: /content/siren/cat_video.mp4\n",
            "\r0.00B [00:00, ?B/s]\r4.49MB [00:00, 39.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taAcFIEQHvDK"
      },
      "source": [
        "os.rename(\"cat_video.mp4\", \"data/cat_video.mp4\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12SEj6nNLM1L"
      },
      "source": [
        "## connect gdrive to colab and redirect logging root"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b_XOVAG5gy9",
        "outputId": "cf84f054-e7fb-4b8d-fe19-ec385f5c3c47"
      },
      "source": [
        "from google.colab import drive\n",
        "drive_dir = '/content/gdrive'\n",
        "drive.mount(drive_dir)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50xuc1NLM_8O",
        "outputId": "7b157661-1435-4194-ceaa-dc4ca1e212a5"
      },
      "source": [
        "logging_root = \"/content/gdrive/MyDrive/siren\"\n",
        "os.makedirs(logging_root, exist_ok=True)\n",
        "osp.isdir(logging_root)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD5kS7kbKI2-"
      },
      "source": [
        "# Easy_Dict is a dictionary accessible as object ( not pypi EasyDict )\n",
        "config_file = \"x_periment_scripts/cat_s-1_100k.yml\"\n",
        "with open(config_file, \"r\") as _fi:\n",
        "    opt = x_utils.EasyDict(yaml.load(_fi,)) # Loader=yaml.FullLoader "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZgrnvp7KKpd",
        "outputId": "1cb639f3-c82e-479a-cb0e-ed510f469489"
      },
      "source": [
        "opt.logging_root = logging_root\n",
        "config_file = \"_colab\".join(osp.splitext(config_file))\n",
        "opt.to_yaml(config_file)\n",
        "print(opt.logging_root, config_file, osp.isfile(config_file))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/siren x_periment_scripts/cat_s-1_100k_colab.yml True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfiO5Qp-OoqA"
      },
      "source": [
        "### training options differ from main branch: containing:\n",
        "* model definition\n",
        "* strategy  [-1] original, fully random single sample per epoch\n",
        " [1] complete set of non repeating samples per epoch [2] grided sampling, dense and sparse : original strategy works best\n",
        "* sample_frac: None, is estimated from GPU available\n",
        "* sample_size: estimated below\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yOdoWVnQ4v0"
      },
      "source": [
        "gpus = x_utils.GPUse()\n",
        "# sample size is multiplied * 2 over the estimate, probably gradient operations over latents are optimized\n",
        "# ergo single operations (sin, +, *) do not save full new latent gradient \n",
        "opt.sample_size = x_utils.estimate_samples(gpus.available, **opt[\"siren\"])*2 \n",
        "opt.epochs_til_checkpoint = 5000 # lower epochs till checkpoint, just in case, colab may boot us out"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSbvTpC9OPEv",
        "outputId": "79301fba-ec58-424e-a3c3-a6d566b6d33f"
      },
      "source": [
        "opt"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 1,\n",
              " 'checkpoint_path': None,\n",
              " 'data_path': './data/cat_video.mp4',\n",
              " 'epochs_til_checkpoint': 5000,\n",
              " 'experiment_name': 'cat_s-1_100k',\n",
              " 'frame_range': None,\n",
              " 'logging_root': '/content/gdrive/MyDrive/siren',\n",
              " 'lr': 0.0001,\n",
              " 'model_type': 'sine',\n",
              " 'num_epochs': 100000,\n",
              " 'num_steps': 100000,\n",
              " 'sample_frac': None,\n",
              " 'sample_size': 321482,\n",
              " 'shuffle': 1,\n",
              " 'siren': {'first_omega_0': 30,\n",
              "  'hidden_features': 1024,\n",
              "  'hidden_layers': 3,\n",
              "  'hidden_omega_0': 30.0,\n",
              "  'in_features': 3,\n",
              "  'out_features': 3,\n",
              "  'outermost_linear': True},\n",
              " 'steps_til_summary': 1,\n",
              " 'strategy': -1,\n",
              " 'train_type': 'video',\n",
              " 'verbose': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGFP3-YhRL5z"
      },
      "source": [
        "## in this instance, sample_size is estimated at 321,480 float32\n",
        "~2x the spec on the paper (160,000) \n",
        "\n",
        "**Does this mean that instead of 100k iterations similar loss will be reaches in 50k operations?**\n",
        "\n",
        "Running the same experiments with the other strategies demonstrates that the a uniform random sampling (i.e. original strategy, -1), has  nearly monotonic convergence whereas running randomly repeating grids (strategy 2) or, non repeating complete random samples over the data ( strategy 1), overfits some data. \n",
        "\n",
        "These experimients will not be run here but to test wsuffices to set opt.strategy = 1 or 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecA-0JDAUrrk"
      },
      "source": [
        "# VideoDataset is modificiation over main branch.\n",
        "* Does not create m_grid then referenceit but finds grid pos from random index\n",
        "* different strategies. see x_dataio.VideoDataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJdypD4CUfFK",
        "outputId": "716d4660-4764-447f-c2e2-a5eb0ca87dad"
      },
      "source": [
        "dset = x_dataio.VideoDataset(opt.data_path, sample_size=opt.sample_size, frame_range=opt.frame_range, strategy=opt.strategy)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Siren: VideoDataset - INFO - Loaded data, sidelen: [300, 512, 512], channels 3\n",
            "Siren: VideoDataset - INFO -          => reshaped to: (78643200, 3)\n",
            "Siren: VideoDataset - INFO -  max sample_size, 321482, fraction, 0.0041\n",
            "Siren: VideoDataset - INFO -  strategy: -1, single sample per epoch\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUqjaPR-VSRr"
      },
      "source": [
        "dataloader = torch.utils.data.DataLoader(dset, shuffle=opt.shuffle, batch_size=1, pin_memory=True, num_workers=0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuSHorhBV0ii"
      },
      "source": [
        "## store training options to yaml"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CexsgjlyVqQ2"
      },
      "source": [
        "opt.sidelen = tuple(dset.data.shape[:-1])\n",
        "opt.chanels = dset.data.shape[-1]\n",
        "opt.sample_size = dset.sample_size\n",
        "opt.dset_len = len(dset)\n",
        "if \"num_steps\" not in opt:\n",
        "    opt.num_steps = None\n",
        "folder = osp.join(opt.logging_root, opt.experiment_name)\n",
        "opt.to_yaml(osp.join(folder, \"training_options.yml\"))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUZhrPwbV6zh"
      },
      "source": [
        "## create model and run\n",
        "Siren used in this instance is simplified - meta nodes disabled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uq0lxdHeV_Im",
        "outputId": "b4d4f18d-a333-490a-886f-7e2fb9333181"
      },
      "source": [
        "model = x_modules.Siren(**opt[\"siren\"])\n",
        "model.cuda()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Siren(\n",
              "  (net): Sequential(\n",
              "    (0): SineLayer(\n",
              "      (linear): Linear(in_features=3, out_features=1024, bias=True)\n",
              "    )\n",
              "    (1): SineLayer(\n",
              "      (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (2): SineLayer(\n",
              "      (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (3): SineLayer(\n",
              "      (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (4): Linear(in_features=1024, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1JMi4zmvjGL"
      },
      "source": [
        "# Process suspendend, at 2.09s/iteration, 100k: ~57 hours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1C1fmI0WT4A",
        "outputId": "4a6e642b-622d-467d-e893-22d798c2a294"
      },
      "source": [
        "checkpoint = train(model, dataloader, opt.num_epochs, opt.lr, opt.epochs_til_checkpoint, folder, dataset=dset,\n",
        "                   num_steps=opt.num_steps, steps_til_summary=100, terminator={\"end\":\"\\n\"})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch\tIter\tIterAll\ttGPU\tGPU\tCPU\tLoss\tTime\tTotal_Time\n",
            "999\t0\t999\t13878\t14962\t4047\t0.0176\t2.09\t2086\n",
            "1999\t0\t1999\t13878\t14962\t4059\t0.0149\t2.09\t4183\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}